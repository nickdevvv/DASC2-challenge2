{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import asarray\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# See TensorFlow version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a65954",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../data/fruits-360/'\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "train_dir = os.path.join(base_dir, 'Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8273d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_count = sum(len(files) for _, _, files in os.walk(train_dir))\n",
    "test_img_count = sum(len(files) for _, _, files in os.walk(test_dir))\n",
    "\n",
    "print(f'Number of files in the training folder: {train_img_count}')\n",
    "print(f'Number of files in the test folder: {test_img_count}\\n')\n",
    "\n",
    "nr_classes = sorted((f for f in os.listdir(train_dir) if not f.startswith(\".\")), key=str.lower)\n",
    "\n",
    "print(f'Number of classes: {len(nr_classes)}')\n",
    "print(f'Names of classes: {nr_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceed59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path(train_dir)\n",
    "test_dir = pathlib.Path(test_dir)\n",
    "\n",
    "fruit6 = ['Kiwi', 'Pear', 'Peach', 'Avocado', 'Blueberry', 'Tomato 3']\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i,fruit in enumerate (fruit6):    \n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    fruit_list = list(train_dir.glob(fruit + '/*'))\n",
    "    \n",
    "    plt.imshow(Image.open(str(fruit_list[i])))\n",
    "    plt.title(fruit6[i])\n",
    "    plt.axis(\"off\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b392bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "def load_fruits360(path):\n",
    "    data_loading = load_files(path)\n",
    "    files = np.array(data_loading['filenames'])\n",
    "    target_fruits = np.array(data_loading['target'])\n",
    "    target_labels_fruits = np.array(data_loading['target_names'])\n",
    "    \n",
    "    return files, target_fruits, target_labels_fruits\n",
    "\n",
    "X_train, y_train, target_labels = load_fruits360(train_dir)\n",
    "X_test, y_test, _ = load_fruits360(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ed617",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of classes: {len(np.unique(y_train))}')\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the test set into validation and test set (ratio 1/2)\n",
    "\n",
    "#X_test, X_valid = X_test[11344:],X_test[:11344]\n",
    "#y_test, y_vaild = y_test[11344:],y_test[:11344]\n",
    "\n",
    "# Splitting the training set into validation and training set (10000 validation)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid  = train_test_split(X_train, y_train, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_nparray(files):\n",
    "    images = []\n",
    "    for file in files:\n",
    "        images.append(asarray(Image.open(file)))\n",
    "    return images\n",
    "\n",
    "X_train = np.array(convert_image_to_nparray(X_train))\n",
    "print(f'Training set shape: {X_train.shape}')\n",
    "\n",
    "X_valid = np.array(convert_image_to_nparray(X_valid))\n",
    "print(f'Validation set shape: {X_valid.shape}')\n",
    "\n",
    "X_test = np.array(convert_image_to_nparray(X_test))\n",
    "print(f'Test set shape: {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nr classes, image height and width\n",
    "\n",
    "num_classes = len(target_labels)\n",
    "\n",
    "img_height = 100\n",
    "img_width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model \n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(\n",
    "  X_train, # Train images\n",
    "  y_train, # Train labels\n",
    "  batch_size = 32,\n",
    "  epochs = 10,\n",
    "  validation_data = (X_valid, y_valid), # Validation images & labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on test set\n",
    "\n",
    "accuracy = model.evaluate(X_test, y_test) # Test the model\n",
    "print(f'Test accuracy: {accuracy[1]:.3f}')\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02309259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "model.save('../models/cnn-split-train-val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9926864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open('models.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d80bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "# model = keras.models.load_model('../models/cnn') # Load model\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca65f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random images with predictions scores\n",
    "\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "for i, idx in enumerate(np.random.choice(X_test.shape[0], size=16, replace=False)):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(X_test[idx]))\n",
    "    pred_idx = np.argmax(predictions[idx])\n",
    "    score = tf.nn.softmax(predictions[idx])\n",
    "    ax.set_title(\"{}, Confidence: {:.2f}\".format(target_labels[pred_idx], 100 * np.max(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a618523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation to avoid overfitting -> create new neural network (add dropout layer)\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "  ]\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes, name=\"outputs\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase epochs - training stops \n",
    "\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  batch_size = 32,\n",
    "  epochs = 10,\n",
    "  validation_data = (X_valid, y_valid),\n",
    "  verbose = 1 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/cnn-data-augmented') # Save model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c3d60751ac06a49151021d7295e62ca50ac53f99ffa0d298fb8b93ccc0dc450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
